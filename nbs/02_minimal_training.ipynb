{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal example of exponential growth of the trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_deep_rnn.core import *\n",
    "from fast_deep_rnn.common_core import *\n",
    "# from fast_deep_rnn.core_v2 import *\n",
    "from fast_deep_rnn.sort_training import *\n",
    "\n",
    "from typing import List, Optional, Union, Callable\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Operations:\n",
    "LinearLayer\n",
    "TanhFunction\n",
    "HStack\n",
    "Sum\n",
    "Row\n",
    "Embedding\n",
    "CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(Module):\n",
    "    def __init__(self, state_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.linear1 = LinearLayer(state_size, hidden_size)\n",
    "        self.linear2 = LinearLayer(state_size, hidden_size)\n",
    "        self.tanh = TanhFunction()\n",
    "        self.hstack = HStack()\n",
    "        self.sum = Sum()\n",
    "        self.register_parameters([self.linear1, self.linear2])\n",
    "\n",
    "    def forward(self, x: Tensor, h_t_1: Optional[Tensor] = None):\n",
    "        X = self.hstack(x, h_t_1)\n",
    "        z1 = self.linear1(X)\n",
    "        z2 = self.linear2(X)\n",
    "        z = self.sum(z1, z2)\n",
    "        h_t = self.tanh(z)\n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.state_size = input_size + hidden_size\n",
    "        self.rnn = RNNCell(self.state_size, hidden_size)\n",
    "        self. row = Row()\n",
    "        self.vstack = VStack()\n",
    "        self.register_parameters([self.rnn])\n",
    "\n",
    "    def forward(self, x: Tensor, h_t_1: Optional[Tensor] = None):\n",
    "        seq_len, batch_size, input_size = x.shape\n",
    "        # print(f'seq_len: {seq_len} batch_size: {batch_size} input_size: {input_size}')\n",
    "        h = Tensor(np.zeros((0, batch_size, self.hidden_size)), name=\"h\")\n",
    "        if h_t_1 is None:\n",
    "            h_t_1 = Tensor(np.zeros((batch_size, self.hidden_size)), name=\"h_t_1\")\n",
    "        for idx in range(seq_len):\n",
    "            h_t_1 = self.rnn.forward(self.row(x, idx), h_t_1)\n",
    "            h = self.vstack(h, h_t_1.reshape((1, batch_size, self.hidden_size)))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNetwork(Module):\n",
    "    def __init__(self, vocab_size: int, emb_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = Embedding(vocab_size, emb_size)\n",
    "        self.rnn = RNN(emb_size, hidden_size)\n",
    "        self.linear = LinearLayer(hidden_size, vocab_size)\n",
    "        xavier_(self.linear.parameters)\n",
    "        self.register_parameters([self.embedding, self.rnn, self.linear])\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        emb = self.embedding(x)\n",
    "        rnn_out = self.rnn(emb)\n",
    "        linear_out = self.linear(rnn_out.reshape(-1, self.hidden_size))\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 20\n",
    "hidden_size = 32\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "max_number = 10\n",
    "\n",
    "model = RecurrentNetwork(vocab_size, emb_size, hidden_size)\n",
    "optimizer = SGD(model.parameters, lr=1.0)\n",
    "loss_function = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_examples = 5\n",
    "seq_len = 2\n",
    "\n",
    "X_val, y_val = get_examples(seq_len, num_examples, max_number)\n",
    "X_val, y_val = X_val.transpose(1, 0), y_val.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: Start -- E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed\n",
      "[0]: Elapsed time: 0.4s\n",
      "[1]: Start -- weights\n",
      "Gradient check passed\n",
      "[1]: Elapsed time: 3.8s\n",
      "[2]: Start -- bias\n",
      "Gradient check passed\n",
      "[2]: Elapsed time: 0.1s\n",
      "[3]: Start -- weights\n",
      "Gradient check passed\n",
      "[3]: Elapsed time: 2.1s\n",
      "[4]: Start -- bias\n",
      "Gradient check passed\n",
      "[4]: Elapsed time: 0.0s\n",
      "[5]: Start -- weights\n",
      "Gradient check passed\n",
      "[5]: Elapsed time: 0.4s\n",
      "[6]: Start -- bias\n",
      "Gradient check passed\n",
      "[6]: Elapsed time: 0.0s\n",
      "Total elapsed time: 6.7s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "loss_function = CrossEntropyLoss()\n",
    "model_ = RecurrentNetwork(vocab_size, emb_size, hidden_size)\n",
    "dJ_theta_tensors = dJ_theta_global(model_, loss_function, Tensor(X_val), Tensor(y_val))\n",
    "global_start = time.time()\n",
    "for i, parameter in enumerate(model_.parameters):\n",
    "    start = time.time()\n",
    "    print(f'[{i}]: Start -- {parameter.__name__}')\n",
    "    def J_theta(theta, idx=i, x=Tensor(X_val), y=Tensor(y_val)):\n",
    "        return J_theta_global(model_, loss_function, theta, idx, x, y)\n",
    "    gradient_checker(J_theta, dJ_theta_tensors[i], parameter.data)\n",
    "    print(f'[{i}]: Elapsed time: {time.time() - start:.1f}s')\n",
    "print(f'Total elapsed time: {time.time() - global_start:.1f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking training and evaluating time step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "num_examples = 1\n",
    "seq_len = 2\n",
    "\n",
    "X_val, y_val = get_examples(seq_len, num_examples, max_number)\n",
    "X_val, y_val = X_val.transpose(1, 0), y_val.transpose(1, 0)\n",
    "X_val, y_val = Tensor(X_val), Tensor(y_val)\n",
    "\n",
    "print(X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 µs ± 64.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# inference step\n",
    "outputs = model(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29 ms ± 253 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# training step\n",
    "outputs = model(X_val)\n",
    "optimizer.zero_grad()\n",
    "loss = loss_function(outputs, y_val)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = range(2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t0.8717286000028253\n",
      "3\t0.8740272999857552\n",
      "4\t1.0663329999952111\n",
      "5\t1.903685500001302\n",
      "6\t1.3410909000085667\n",
      "7\t1.8457453000009991\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "\n",
    "for seq_len in seq_range:\n",
    "    X_val, y_val = get_examples(seq_len, num_examples, max_number)\n",
    "    X_val, y_val = X_val.transpose(1, 0), y_val.transpose(1, 0)\n",
    "    X_val, y_val = Tensor(X_val), Tensor(y_val)\n",
    "    spent_time = timeit.timeit(\"model(X_val)\", globals=globals(), number=1000)\n",
    "    print(seq_len, spent_time, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t1.7819602999952622\n",
      "3\t2.65656190001755\n",
      "4\t4.4321885999816\n",
      "5\t11.626309499988565\n",
      "6\t15.225644200021634\n",
      "7\t30.876693199999863\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for seq_len in seq_range:\n",
    "    X_val, y_val = get_examples(seq_len, num_examples, max_number)\n",
    "    X_val, y_val = X_val.transpose(1, 0), y_val.transpose(1, 0)\n",
    "    X_val, y_val = Tensor(X_val), Tensor(y_val)\n",
    "    spent_time = timeit.timeit(\"\"\"\n",
    "outputs = model(X_val)\n",
    "optimizer.zero_grad()\n",
    "loss = loss_function(outputs, y_val)\n",
    "loss.backward()\n",
    "\"\"\", globals=globals(), number=1000)\n",
    "    print(seq_len, spent_time, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "vocab_size = len(vocab)\n",
    "emb_size = 20\n",
    "hidden_size = 32\n",
    "batch_size = 100\n",
    "dataloader = DataLoader(dataset_inputs, dataset_targets, batch_size=batch_size)\n",
    "model = RecurrentNetwork(vocab_size, emb_size, hidden_size)\n",
    "loss_function = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters, lr=1.0)\n",
    "# optimizer = Adam(model.parameters, alpha=0.1, beta1=0.9, beta2=0.999, eps=1e-8, weight_decay=0.01)\n",
    "scheduler = ConstantLR(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4028"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: [1/1], loss: 16.224544255535776, acc: 0.68125"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "lrs = []\n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "    for data in dataloader():\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data\n",
    "        inputs = inputs.transpose(1, 0)\n",
    "        targets = targets.transpose(1, 0)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.data\n",
    "    acc = eval_accuracy(model, inputs.data, targets.data)\n",
    "    print(f'\\r epoch: [{epoch+1}/{num_epochs}], loss: {loss_sum}, acc: {acc}', end='')\n",
    "    losses.append(loss_sum)\n",
    "    accuracies.append(acc)\n",
    "    lrs.append(scheduler.lr)\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
